"""
PyCUDA Compiler - CUDA Code Generator

Генерирует CUDA C++ код из IR.
"""

from __future__ import annotations
from typing import Dict, Optional, Set
from types_ir import (
    CUDAType, TypeKind,
    IRNode, IRModule, IRStructDef, IRFunctionDef, IRVarDecl,
    IRAssign, IRAugAssign, IRIf, IRFor, IRParallelFor, IRWhile,
    IRReturn, IRBreak, IRContinue, IRExprStmt, IRBlock,
    IRConst, IRVar, IRBinOp, IRUnaryOp, IRCompare,
    IRCall, IRMethodCall, IRIndex, IRAttr, IRTernary, IRCast,
    IRArrayInit, IRTupleInit, IROptionalInit, IRStructInit, IRTensorSlice, IRArrayAlloc, IRDelete,
    BinaryOp, UnaryOp, CompareOp
)


class CodeGenError(Exception):
    """Ошибка генерации кода."""
    pass


class CUDACodeGen:
    """Генератор CUDA C++ кода."""
    
    # Маппинг Python функций → CUDA
    MATH_FUNCS = {
        'sqrt': 'sqrtf',
        'sin': 'sinf',
        'cos': 'cosf',
        'tan': 'tanf',
        'exp': 'expf',
        'log': 'logf',
        'log2': 'log2f',
        'log10': 'log10f',
        'floor': 'floorf',
        'ceil': 'ceilf',
        'abs': 'fabsf',
        'fabs': 'fabsf',
        'pow': 'powf',
        'min': 'fminf',
        'max': 'fmaxf',
        'asin': 'asinf',
        'acos': 'acosf',
        'atan': 'atanf',
        'atan2': 'atan2f',
        'sinh': 'sinhf',
        'cosh': 'coshf',
        'tanh': 'tanhf',
        'rsqrt': 'rsqrtf',
        'fma': 'fmaf',
    }
    
    # Операторы
    BINOP_STR = {
        BinaryOp.ADD: '+',
        BinaryOp.SUB: '-',
        BinaryOp.MUL: '*',
        BinaryOp.DIV: '/',
        BinaryOp.MOD: '%',
        BinaryOp.FLOORDIV: '/',
        BinaryOp.LSHIFT: '<<',
        BinaryOp.RSHIFT: '>>',
        BinaryOp.BITOR: '|',
        BinaryOp.BITXOR: '^',
        BinaryOp.BITAND: '&',
        BinaryOp.AND: '&&',
        BinaryOp.OR: '||',
    }
    
    UNARYOP_STR = {
        UnaryOp.NEG: '-',
        UnaryOp.POS: '+',
        UnaryOp.NOT: '!',
        UnaryOp.BITNOT: '~',
    }
    
    CMPOP_STR = {
        CompareOp.EQ: '==',
        CompareOp.NE: '!=',
        CompareOp.LT: '<',
        CompareOp.LE: '<=',
        CompareOp.GT: '>',
        CompareOp.GE: '>=',
    }
    
    def __init__(self):
        self.indent_level = 0
        self.indent_str = '    '
        self.structs: Dict[str, IRStructDef] = {}
        self.current_function: Optional[IRFunctionDef] = None
        self.declared_vars: Set[str] = set()
        self.array_sizes: Dict[str, str] = {}
        
    def indent(self) -> str:
        """Возвращает текущий отступ."""
        return self.indent_str * self.indent_level
    
    def type_to_cuda(self, t: CUDAType) -> str:
        """Конвертирует тип в CUDA строку."""
        if t is None:
            return 'float'
        
        if t.kind == TypeKind.VOID:
            return 'void'
        elif t.kind == TypeKind.BOOL:
            return 'bool'
        elif t.kind == TypeKind.INT:
            return t.cuda_name
        elif t.kind == TypeKind.FLOAT:
            return t.cuda_name
        elif t.kind == TypeKind.ARRAY:
            elem = self.type_to_cuda(t.element_type) if t.element_type else 'float'
            return f'{elem}*'
        elif t.kind == TypeKind.LIST:
            # Struct name like List_float32
            elem = self.type_to_cuda(t.element_type) if t.element_type else 'float'
            # Sanitize name for C++ (replace * with Ptr, etc if needed, but simplified for now)
            # basic types are safe.
            return f'List_{t.element_type.name}'
        elif t.kind == TypeKind.POINTER:
            elem = self.type_to_cuda(t.element_type) if t.element_type else 'void'
            return f'{elem}*'
        elif t.kind == TypeKind.TUPLE:
            return t.cuda_name
        elif t.kind == TypeKind.OPTIONAL:
            return t.cuda_name
        elif t.kind == TypeKind.STRING:
            return 'String'
        elif t.kind == TypeKind.DICT:
            return t.cuda_name
        elif t.kind == TypeKind.SET:
            return t.cuda_name
        elif t.kind == TypeKind.STRUCT:
            return t.name
        
        return t.cuda_name or 'float'
    
    def generate(self, module: IRModule) -> str:
        """Генерирует полный CUDA код."""
        lines = []
        
        # Заголовок
        lines.append('// Generated by PyCUDA Compiler')
        lines.append('')
        
        # Helper макросы
        lines.append('// Thread indexing helpers')
        lines.append('#define THREAD_ID (blockIdx.x * blockDim.x + threadIdx.x)')
        lines.append('#define GRID_STRIDE (blockDim.x * gridDim.x)')
        lines.append('')
        
        # Scan for IRArrayAlloc usage to optionally include ScopedArray
        has_array_alloc = False
        def scan_array_alloc(stmt: IRNode):
            nonlocal has_array_alloc
            if has_array_alloc: return
            
            if isinstance(stmt, IRArrayAlloc):
                has_array_alloc = True
                return
            
            # Recursive checks
            if isinstance(stmt, IRAssign):
                scan_array_alloc(stmt.value)
            elif isinstance(stmt, IRAugAssign):
                scan_array_alloc(stmt.value)
            elif isinstance(stmt, IRExprStmt):
                 scan_array_alloc(stmt.expr)
            elif isinstance(stmt, (IRIf, IRWhile)):
                scan_array_alloc(stmt.condition)
                for s in (stmt.then_body if isinstance(stmt, IRIf) else stmt.body):
                     scan_array_alloc(s)
                if isinstance(stmt, IRIf) and stmt.else_body:
                     for s in stmt.else_body: scan_array_alloc(s)
            elif isinstance(stmt, (IRFor, IRParallelFor)):
                 scan_array_alloc(stmt.start)
                 scan_array_alloc(stmt.end)
                 if stmt.step: scan_array_alloc(stmt.step)
                 for s in stmt.body: scan_array_alloc(s)
            elif isinstance(stmt, IRBlock):
                 for s in stmt.statements: scan_array_alloc(s)
            elif isinstance(stmt, IRReturn) and stmt.value:
                 scan_array_alloc(stmt.value)
            elif isinstance(stmt, IRVarDecl) and stmt.init_value:
                 scan_array_alloc(stmt.init_value)
            # Expressions recursions (simplified)
            # Ideally we traverse whole tree.
            # But IRArrayAlloc usually appears in Assign or VarDecl or top level Expr.
        
        for func in module.functions:
            if has_array_alloc: break
            for stmt in func.body:
                scan_array_alloc(stmt)

        # ScopedArray for automatic memory management (RAII)
        if has_array_alloc:
            lines.append("""
template<typename T>
struct ScopedArray {
    T* ptr;
    __device__ ScopedArray() : ptr(nullptr) {}
    __device__ ScopedArray(T* p) : ptr(p) {}
    __device__ ~ScopedArray() { if (ptr) delete[] ptr; }
    
    // Dissable copy to prevent double free
    __device__ ScopedArray(const ScopedArray&) = delete;
    __device__ ScopedArray& operator=(const ScopedArray&) = delete;

    // Move semantics (simplified)
    __device__ ScopedArray& operator=(T* p) { 
        if (ptr) delete[] ptr; 
        ptr = p; 
        return *this; 
    }
    
    __device__ T* release() {
        T* p = ptr;
        ptr = nullptr;
        return p;
    }

    __device__ T& operator[](int i) { return ptr[i]; }
    __device__ const T& operator[](int i) const { return ptr[i]; }
    __device__ operator T*() { return ptr; }
};
""")
            lines.append('')

        # Собираем информацию о структурах
        for struct in module.structs:
            self.structs[struct.name] = struct
        
        # Генерируем определения структур List_T, которые используются
        # Scan module for List types
        list_types = set()
        def scan_type(t: CUDAType):
            if t and t.is_list():
                list_types.add(t)
            if t and t.element_type:
                scan_type(t.element_type)
        
        for func in module.functions:
            for _, t in func.params:
                scan_type(t)
            for _, t in func.local_vars.items():
                scan_type(t)

        for lt in list_types:
            lines.append(self.gen_list_struct_def(lt))
            lines.append('')
        
        # Scan for Tuple types
        tuple_types = set()
        def scan_tuple_types(t: CUDAType):
            if t and t.kind == TypeKind.TUPLE:
                tuple_types.add(t)
                for et in t.element_types:
                    scan_tuple_types(et)
            if t and t.element_type:
                scan_tuple_types(t.element_type)
            if t and t.kind == TypeKind.LIST:
                scan_tuple_types(t.element_type)

        for func in module.functions:
            scan_tuple_types(func.return_type)
            for _, t in func.params:
                scan_tuple_types(t)
            for _, t in func.local_vars.items():
                scan_tuple_types(t)

        # Scan for Optional types
        optional_types = set()
        def scan_optional_types(t: CUDAType):
            if t and t.kind == TypeKind.OPTIONAL:
                optional_types.add(t)
                scan_optional_types(t.element_type)
            if t and t.element_type:
                scan_optional_types(t.element_type)
            if t and t.kind == TypeKind.TUPLE:
                 for et in t.element_types:
                     scan_optional_types(et)
        
        for func in module.functions:
            scan_optional_types(func.return_type)
            for _, t in func.params:
                scan_optional_types(t)
            for _, t in func.local_vars.items():
                scan_optional_types(t)
        
        # Generate Optional struct definitions
        for ot in optional_types:
            lines.append(self.gen_optional_struct_def(ot))
            lines.append('')
            
        # Scan for String usage
        has_string = False
        string_checked = set()
        
        def scan_string(t: Optional[CUDAType]):
             nonlocal has_string
             if has_string or t is None:
                 return
             if t in string_checked:
                 return
             string_checked.add(t)
             
             if t.kind == TypeKind.STRING:
                 has_string = True
                 return
                 
             if t.element_type:
                 scan_string(t.element_type)
             for et in t.element_types:
                 scan_string(et)
                 
        for func in module.functions:
            if has_string:
                break
            scan_string(func.return_type)
            for _, t in func.params:
                scan_string(t)
            for _, t in func.local_vars.items():
                scan_string(t)

        if has_string:
            lines.append(self.gen_string_struct_def())
            lines.append('')
        
        # Scan for Dict types
        dict_types = set()
        def scan_dict_types(t: CUDAType):
            if t and t.kind == TypeKind.DICT:
                dict_types.add(t)
                for et in t.element_types:
                    scan_dict_types(et)
            if t and t.element_type:
                scan_dict_types(t.element_type)
            if t and t.kind == TypeKind.TUPLE:
                 for et in t.element_types:
                     scan_dict_types(et)
        
        for func in module.functions:
            scan_dict_types(func.return_type)
            for _, t in func.params:
                scan_dict_types(t)
            for _, t in func.local_vars.items():
                scan_dict_types(t)

        for dt in dict_types:
            lines.append(self.gen_dict_struct_def(dt))
            lines.append('')
            
        # Scan for Set types
        set_types = set()
        def scan_set_types(t: CUDAType):
            if t and t.kind == TypeKind.SET:
                set_types.add(t)
                if t.element_type:
                    scan_set_types(t.element_type)
            if t and t.element_type:
                scan_set_types(t.element_type)
            if t and t.kind == TypeKind.TUPLE:
                 for et in t.element_types:
                     scan_set_types(et)
        
        for func in module.functions:
            scan_set_types(func.return_type)
            for _, t in func.params:
                scan_set_types(t)
            for _, t in func.local_vars.items():
                scan_set_types(t)
                
        for st in set_types:
            lines.append(self.gen_set_struct_def(st))
            lines.append('')

        # Generate Tuple struct definitions
        for tt in tuple_types:
            lines.append(self.gen_tuple_struct_def(tt))
            lines.append('')
        
        # Генерируем пользовательские структуры
        for struct in module.structs:
            lines.append(self.gen_struct(struct))
            lines.append('')
        
        # Device функции (методы)
        for struct in module.structs:
            for method in struct.methods:
                lines.append(self.gen_function(method))
                lines.append('')
        
        # Глобальные переменные
        for glob in module.globals:
            lines.append(self.gen_global_var(glob))
        if module.globals:
            lines.append('')
        
        # Функции
        for func in module.functions:
            lines.append(self.gen_function(func))
            lines.append('')
        
        return '\n'.join(lines)
    
    def gen_list_struct_def(self, list_type: CUDAType) -> str:
        """Генерирует определение структуры списка (List_T)."""
        elem_type = self.type_to_cuda(list_type.element_type)
        struct_name = self.type_to_cuda(list_type)
        
        return f"""struct {struct_name} {{
    {elem_type}* data;
    int* size;
    int capacity;

    __device__ void append({elem_type} val) {{
        int idx = atomicAdd(size, 1);
        if (idx < capacity) {{
            data[idx] = val;
        }}
    }}
    
    __device__ {elem_type} pop() {{
        int idx = atomicSub(size, 1) - 1;
        if (idx >= 0) {{
             return data[idx];
        }}
        return 0; // Underflow
    }}
    
    __device__ int len() {{
        return *size;
    }}
    
    __device__ void clear() {{
        *size = 0;
    }}
    
    __device__ {elem_type}& operator[](int idx) {{
        return data[idx];
    }}
}};"""

    def gen_tuple_struct_def(self, t: CUDAType) -> str:
        """Generates definition for a Tuple struct."""
        lines = []
        lines.append(f'struct {t.cuda_name} {{')
        for i, et in enumerate(t.element_types):
            e_cuda = self.type_to_cuda(et)
            lines.append(f'{self.indent_str}{e_cuda} f{i};')
        
        # Constructor
        params = [f'{self.type_to_cuda(et)} _f{i}' for i, et in enumerate(t.element_types)]
        inits = [f'f{i}(_f{i})' for i in range(len(t.element_types))]
        lines.append(f'{self.indent_str}__device__ {t.cuda_name}({", ".join(params)}) : {", ".join(inits)} {{}}')
        # Default Constructor
        lines.append(f'{self.indent_str}__device__ {t.cuda_name}() {{}}')

        lines.append('};')
        return '\n'.join(lines)
    
    def gen_struct(self, struct: IRStructDef) -> str:
        """Генерирует структуру."""
        lines = []
        lines.append(f'struct {struct.name} {{')
        
        for field_name, field_type in struct.fields:
            cuda_type = self.type_to_cuda(field_type)
            lines.append(f'{self.indent_str}{cuda_type} {field_name};')
        
        lines.append('};')
        return '\n'.join(lines)
    
    def gen_global_var(self, var: IRVarDecl) -> str:
        """Генерирует глобальную переменную."""
        cuda_type = self.type_to_cuda(var.var_type)
        if var.init_value:
            init = self.gen_expr(var.init_value)
            return f'__device__ {cuda_type} {var.name} = {init};'
        return f'__device__ {cuda_type} {var.name};'
    
    def gen_function(self, func: IRFunctionDef) -> str:
        """Генерирует функцию."""
        self.current_function = func
        self.declared_vars = set()
        self.array_sizes = {}
        
        lines = []
        
        # Сигнатура
        prefix = ''
        # Сигнатура
        prefix = ''
        if func.is_kernel:
            prefix = 'extern "C" __global__'
        elif func.is_device or func.is_method:
            prefix = '__device__'
        
        return_type = self.type_to_cuda(func.return_type)
        if func.is_kernel:
            return_type = 'void'
        
        # Имя функции
        func_name = func.name
        if func.is_method and func.parent_class:
            func_name = f'{func.parent_class}_{func.name}'
        
        # Параметры
        params = []
        preamble = [] # Code to reconstruct objects at start of function
        
        # self для методов
        if func.is_method and func.parent_class:
            params.append(f'{func.parent_class}* self')
        
        for param_name, param_type in func.params:
            if param_type.is_list() and func.is_kernel:
                # Expand List args for kernels: T* data, int* size, int cap
                cuda_type_name = self.type_to_cuda(param_type)
                elem_type = self.type_to_cuda(param_type.element_type)
                
                p_data = f'{param_name}_data'
                p_size = f'{param_name}_size'
                p_cap = f'{param_name}_cap'
                
                params.append(f'{elem_type}* {p_data}')
                params.append(f'int* {p_size}')
                params.append(f'int {p_cap}')
                
                # Reconstruct struct
                preamble.append(f'{self.indent_str}{cuda_type_name} {param_name} = {{ {p_data}, {p_size}, {p_cap} }};')
                self.declared_vars.add(param_name)
                
            else:
                cuda_type = self.type_to_cuda(param_type)
                params.append(f'{cuda_type} {param_name}')
                self.declared_vars.add(param_name)
                
                # Для массивов добавляем размер (старая логика)
                if param_type.is_tensor():
                    rank = param_type.rank
                    for i in range(rank):
                        params.append(f'int _shape_{param_name}_{i}')
                        params.append(f'int _stride_{param_name}_{i}')
                elif param_type.is_array() or param_type.is_pointer():
                    size_name = f'_size_{param_name}'
                    params.append(f'int {size_name}')
                    self.array_sizes[param_name] = size_name
                    self.declared_vars.add(size_name)
        
        args_str = ', '.join(params)
        lines.append(f'{prefix} {return_type} {func_name}({args_str}) {{')
        
        self.indent_level = 1
        
        # Preamble (List reconstruction, etc)
        for p in preamble:
            lines.append(p)
        
        # Identify variables that are allocated arrays (owning)
        # We scan assignments to find variables assigned from IRArrayAlloc
        self.owning_arrays = set()
        
        def scan_owning(stmt: IRNode):
            if isinstance(stmt, IRAssign):
                if isinstance(stmt.value, IRArrayAlloc):
                    if isinstance(stmt.target, IRVar):
                        self.owning_arrays.add(stmt.target.name)
            elif isinstance(stmt, IRIf):
                for s in stmt.then_body: scan_owning(s)
                for s in stmt.else_body: scan_owning(s)
            elif isinstance(stmt, (IRFor, IRParallelFor, IRWhile)):
                for s in stmt.body: scan_owning(s)
            elif isinstance(stmt, IRBlock):
                for s in stmt.statements: scan_owning(s)
                
        for stmt in func.body:
             scan_owning(stmt)

        # Объявление локальных переменных
        for var_name, var_type in func.local_vars.items():
            if var_name in self.declared_vars:
                continue
            
            # Skip loop variables (they are declared in for loop usually, but check if we track them?)
            # TypeInference puts them in local_vars.
            # But gen_for declares them: for(int i=...)
            # We should assume if it's INT and commonly used as loop var, we might skip declaration if it collides.
            # But standard C declarations at top are safe if shadows or reused.
            # However, `gen_for` uses `int var = ...`. Re-declaration is error.
            # We should validly NOT declare it at top.
            
            # Simple heuristic: don't declare loop vars here?
            # Or track loop vars in scan?
            # Let's trust that if it is in local_vars, it needs declaration unless it is loop var.
            # The user code `i` in loop is loop var.
            
            # Check if this var is owning array
            if var_name in self.owning_arrays and var_type and (var_type.is_array() or var_type.is_pointer()):
                # Declaring as ScopedArray<ElementType>
                # var_type is T* (pointer to element)
                elem_type = self.type_to_cuda(var_type.element_type) if var_type.element_type else 'float'
                lines.append(f'{self.indent()}ScopedArray<{elem_type}> {var_name};')
            else:
                # Regular declaration
                # Check for loop vars? To avoid re-definition error.
                # Just declare them. If gen_for re-declares `int i`, it shadows `int i` at top scope.
                # Valid in C++, though warning-prone.
                
                # Check if it was param?
                param_names = [p[0] for p in func.params]
                if var_name in param_names:
                    continue

                if var_name == 'self': continue

                cuda_type = self.type_to_cuda(var_type)
                lines.append(f'{self.indent()}{cuda_type} {var_name};')
            
            self.declared_vars.add(var_name)
        
        # Тело функции (удаляем пустые строки для красоты)
        for stmt in func.body:
            code = self.gen_stmt(stmt)
            if code:
                lines.append(code)
        
        self.indent_level -= 1
        lines.append('}')
        
        self.current_function = None
        return '\n'.join(lines)
    
    def gen_stmt(self, stmt: IRNode) -> str:
        """Генерирует statement."""
        if isinstance(stmt, IRAssign):
            return self.gen_assign(stmt)
        elif isinstance(stmt, IRAugAssign):
            return self.gen_aug_assign(stmt)
        elif isinstance(stmt, IRVarDecl):
            return self.gen_var_decl(stmt)
        elif isinstance(stmt, IRIf):
            return self.gen_if(stmt)
        elif isinstance(stmt, IRFor):
            return self.gen_for(stmt)
        elif isinstance(stmt, IRParallelFor):
            return self.gen_parallel_for(stmt)
        elif isinstance(stmt, IRWhile):
            return self.gen_while(stmt)
        elif isinstance(stmt, IRReturn):
            return self.gen_return(stmt)
        elif isinstance(stmt, IRBreak):
            return f'{self.indent()}break;'
        elif isinstance(stmt, IRContinue):
            return f'{self.indent()}continue;'
        elif isinstance(stmt, IRExprStmt):
            return f'{self.indent()}{self.gen_expr(stmt.expr)};'
        elif isinstance(stmt, IRBlock):
            return self.gen_block(stmt)
        elif isinstance(stmt, IRDelete):
            return self.gen_delete(stmt)
        return ''
    
    def gen_assign(self, stmt: IRAssign) -> str:
        """Генерирует присваивание."""
        target = self.gen_expr(stmt.target)
        value = self.gen_expr(stmt.value)
        return f'{self.indent()}{target} = {value};'
    
    def gen_aug_assign(self, stmt: IRAugAssign) -> str:
        """Генерирует +=."""
        target = self.gen_expr(stmt.target)
        value = self.gen_expr(stmt.value)
        op = self.BINOP_STR.get(stmt.op, '+')
        return f'{self.indent()}{target} {op}= {value};'
    
    def gen_var_decl(self, stmt: IRVarDecl) -> str:
        """Генерирует объявление переменной."""
        if stmt.name in self.declared_vars:
            if stmt.init_value:
                return f'{self.indent()}{stmt.name} = {self.gen_expr(stmt.init_value)};'
            return ''
        
        cuda_type = self.type_to_cuda(stmt.var_type)
        self.declared_vars.add(stmt.name)
        
        if stmt.init_value:
            return f'{self.indent()}{cuda_type} {stmt.name} = {self.gen_expr(stmt.init_value)};'
        return f'{self.indent()}{cuda_type} {stmt.name};'
    
    def gen_if(self, stmt: IRIf) -> str:
        """Генерирует if."""
        lines = []
        cond = self.gen_expr(stmt.condition)
        lines.append(f'{self.indent()}if ({cond}) {{')
        
        self.indent_level += 1
        for s in stmt.then_body:
            code = self.gen_stmt(s)
            if code:
                lines.append(code)
        self.indent_level -= 1
        
        if stmt.else_body:
            lines.append(f'{self.indent()}}} else {{')
            self.indent_level += 1
            for s in stmt.else_body:
                code = self.gen_stmt(s)
                if code:
                    lines.append(code)
            self.indent_level -= 1
        
        lines.append(f'{self.indent()}}}')
        return '\n'.join(lines)
    
    def gen_for(self, stmt: IRFor) -> str:
        """Генерирует ordinary or parallel for."""
        lines = []
        
        var = stmt.var_name
        start = self.gen_expr(stmt.start)
        end = self.gen_expr(stmt.end)
        step = self.gen_expr(stmt.step) if stmt.step else '1'
        
        # Determine comparison operator
        if isinstance(stmt.step, IRConst) and stmt.step.value < 0:
            cmp = '>'
        else:
            cmp = '<'

        if stmt.is_parallel:
            # Grid-Stride Loop Logic
            # for (int var = start + THREAD_ID * step; var < end; var += GRID_STRIDE * step)
            init = f"{start} + THREAD_ID * ({step})"
            incr = f"GRID_STRIDE * ({step})"
            lines.append(f'{self.indent()}for (int {var} = {init}; {var} {cmp} {end}; {var} += {incr}) {{')
        else:
            # Standard Loop
            lines.append(f'{self.indent()}for (int {var} = {start}; {var} {cmp} {end}; {var} += {step}) {{')
        
        self.indent_level += 1
        for s in stmt.body:
            code = self.gen_stmt(s)
            if code:
                lines.append(code)
        self.indent_level -= 1
        
        lines.append(f'{self.indent()}}}')
        return '\n'.join(lines)
    
    def gen_parallel_for(self, stmt: IRParallelFor) -> str:
        """Генерирует параллельный for (CUDA grid-stride loop)."""
        lines = []
        
        var = stmt.var_name
        
        # Определяем размер
        size_expr = stmt.size_expr
        if size_expr is None:
             # Try to find size from loop range
             size_expr = IRBinOp(stmt.end, BinaryOp.SUB, stmt.start) # approx
        
        size = self.gen_expr(size_expr)
        
        lines.append(f'{self.indent()}int _stride = GRID_STRIDE;')
        lines.append(f'{self.indent()}for (int {var} = THREAD_ID; {var} < {size}; {var} += _stride) {{')
        
        self.indent_level += 1
        for s in stmt.body:
            code = self.gen_stmt(s)
            if code:
                lines.append(code)
        self.indent_level -= 1
        
        lines.append(f'{self.indent()}}}')
        return '\n'.join(lines)
    
    def gen_while(self, stmt: IRWhile) -> str:
        """Генерирует while."""
        lines = []
        cond = self.gen_expr(stmt.condition)
        lines.append(f'{self.indent()}while ({cond}) {{')
        
        self.indent_level += 1
        for s in stmt.body:
            code = self.gen_stmt(s)
            if code:
                lines.append(code)
        self.indent_level -= 1
        
        lines.append(f'{self.indent()}}}')
        return '\n'.join(lines)
    
    def gen_move_expr(self, expr: IRNode) -> str:
        """
        Генерирует выражение с семантикой перемещения (move semantics) для return.
        Если встречает ScopedArray переменную, вызывает .release().
        """
        if isinstance(expr, IRVar) and expr.name in self.owning_arrays:
            return f'{expr.name}.release()'
        
        elif isinstance(expr, IRTupleInit):
            elements = [self.gen_move_expr(e) for e in expr.elements]
            return f'{expr.type.cuda_name}({", ".join(elements)})'
        
        elif isinstance(expr, IRStructInit):
            # Struct init logic (similar to gen_struct_init but recursive move)
            # Assuming implicit constructor usage or explicit?
            # gen_struct_init currently not shown fully but likely uses constructor.
            # Only if struct has constructor with fields.
            # My generated structs don't seem to have constructor for fields by default unless Tuple?
            # Wait, gen_struct generates POD struct.
            # Initializer list: StructType{ f1, f2 }
            # So we can use initializer list syntax.
             args = []
             # We need to know field order.
             # We have expr.values (dict?) or list?
             # IRStructInit definition:
             # struct_name: str, values: Dict[str, IRNode]
             # We need to look up struct definition to order fields.
             struct_def = self.structs.get(expr.struct_name)
             if struct_def:
                 for field, _ in struct_def.fields:
                     val = expr.values.get(field)
                     if val:
                         args.append(self.gen_move_expr(val))
                     else:
                         args.append('0') # Default?
                 return f'{expr.struct_name}{{{", ".join(args)}}}'
             return self.gen_expr(expr) # Fallback

        elif isinstance(expr, IROptionalInit):
             if expr.value is None:
                 return f'{expr.type.cuda_name}()'
             val = self.gen_move_expr(expr.value)
             return f'{expr.type.cuda_name}({val})'

        # Default to normal gen_expr for others
        return self.gen_expr(expr)

    def gen_return(self, stmt: IRReturn) -> str:
        """Генерирует return."""
        if stmt.value:
            if self.current_function and self.current_function.is_kernel:
                raise CodeGenError("CUDA kernels cannot return values. Please use output arrays (arguments).")
            
            # Use move semantics for return value to support ScopedArray release within tuples/structs
            val = self.gen_move_expr(stmt.value)
            return f'{self.indent()}return {val};'
        return f'{self.indent()}return;'
    
    def gen_block(self, stmt: IRBlock) -> str:
        """Генерирует блок."""
        lines = []
        lines.append(f'{self.indent()}{{')
        self.indent_level += 1
        for s in stmt.statements:
            code = self.gen_stmt(s)
            if code:
                lines.append(code)
        self.indent_level -= 1
        lines.append(f'{self.indent()}}}')
        return '\n'.join(lines)
    
    def gen_delete(self, stmt: IRDelete) -> str:
        """Генерирует delete."""
        target = self.gen_expr(stmt.target)
        
        # Determine if we should use delete or delete[]
        # Based on type. 
        # If unknown, default to delete[] for pointer safety if allocated with new[]?
        # Actually delete[] is required for new[].
        # Arrays are pointers.
        # But single objects are also pointers (structs).
        # We need rigorous type checking.
        
        is_array = False
        if stmt.target.type:
             # Check if it is a pointer to an array?
             # IRArrayAlloc returns pointer to ElementType.
             # So it's just a T*. 
             # In C++, T* can be array or single object.
             # We assume del is used for arrays if it's a pointer.
             # IF the user allocated with new T(), they should use del?
             # For now, let's look at type kind.
             # If it points to a Struct, maybe single object?
             # But we can create array of structs.
             # Convention: del x -> delete[] x;
             # Unless we know for sure it's a single object?
             # If we want to support both, we might need syntax or tracking.
             # Given numpy arrays are the main dynamic allocation, delete[] is safer default.
             is_array = True
        
        if is_array:
            return f'{self.indent()}delete[] {target};'
        else:
            return f'{self.indent()}delete {target};'
    
    def gen_expr(self, expr: IRNode) -> str:
        """Генерирует выражение."""
        if expr is None:
            return '0'
        
        if isinstance(expr, IRConst):
            return self.gen_const(expr)
        elif isinstance(expr, IRVar):
            return expr.name
        elif isinstance(expr, IRBinOp):
            return self.gen_binop(expr)
        elif isinstance(expr, IRUnaryOp):
            return self.gen_unaryop(expr)
        elif isinstance(expr, IRCompare):
            return self.gen_compare(expr)
        elif isinstance(expr, IRCall):
            return self.gen_call(expr)
        elif isinstance(expr, IRMethodCall):
            return self.gen_method_call(expr)
        elif isinstance(expr, IRIndex):
            return self.gen_index(expr)
        elif isinstance(expr, IRAttr):
            return self.gen_attr(expr)
        elif isinstance(expr, IRTernary):
            return self.gen_ternary(expr)
        elif isinstance(expr, IRCast):
            return self.gen_cast(expr)
        elif isinstance(expr, IRArrayInit):
            return self.gen_array_init(expr)
        elif isinstance(expr, IRStructInit):
            return self.gen_struct_init(expr)
        elif isinstance(expr, IRTupleInit):
            return self.gen_tuple_init(expr)
        elif isinstance(expr, IRTensorSlice):
            return self.gen_tensor_slice(expr)
        elif isinstance(expr, IROptionalInit):
            return self.gen_optional_init(expr)
        elif isinstance(expr, IRArrayAlloc):
            return self.gen_array_alloc(expr)
        
        return '/* unknown */'
    
    def gen_tensor_slice(self, expr: IRTensorSlice) -> str:
        """Генерирует срез тензора (pointer arithmetic)."""
        base = self.gen_expr(expr.obj)
        offset_parts = []
        
        for i, idx in enumerate(expr.slices):
             real_dim = expr.dim_offset + i
             idx_str = self.gen_expr(idx)
             # Use the stride name logic
             stride_name = f"_stride_{expr.base_name}_{real_dim}"
             offset_parts.append(f"({idx_str} * {stride_name})")
             # Note: declared_vars check is implicit? 
             # Argument variables (like strides) are always available in the function scope.
        
        offset = " + ".join(offset_parts)
        if not offset:
            offset = "0"
            
        # Determine if result is pointer or value
        # If result type has rank > 0 or is pointer -> offset arithmetic
        if expr.type.is_array() or expr.type.is_pointer() or expr.type.is_tensor():
             return f"({base} + {offset})"
        else: # Scalar access
             return f"{base}[{offset}]"
    
    def gen_const(self, expr: IRConst) -> str:
        """Генерирует константу."""
        value = expr.value
        if isinstance(value, bool):
            return 'true' if value else 'false'
        elif isinstance(value, float):
            return f'{value}f'
        elif isinstance(value, str):
            return f'String("{value}")'
        else:
            return str(value)
    
    def gen_binop(self, expr: IRBinOp) -> str:
        """Генерирует бинарную операцию."""
        left = self.gen_expr(expr.left)
        right = self.gen_expr(expr.right)
        
        if expr.op == BinaryOp.POW:
            return f'powf({left}, {right})'
        if expr.op == BinaryOp.FLOORDIV:
            return f'(int)({left} / {right})'
        
        op = self.BINOP_STR.get(expr.op, '+')
        return f'({left} {op} {right})'
    
    def gen_unaryop(self, expr: IRUnaryOp) -> str:
        """Генерирует унарную операцию."""
        operand = self.gen_expr(expr.operand)
        op = self.UNARYOP_STR.get(expr.op, '-')
        return f'({op}{operand})'
    
    def gen_compare(self, expr: IRCompare) -> str:
        """Генерирует сравнение."""
        # Handle 'in' / 'not in'
        if expr.op == CompareOp.IN:
             # left in right -> right.contains(left)
             return f'{self.gen_expr(expr.right)}.contains({self.gen_expr(expr.left)})'
        if expr.op == CompareOp.NOT_IN:
             return f'!{self.gen_expr(expr.right)}.contains({self.gen_expr(expr.left)})'

        left = self.gen_expr(expr.left)
        right = self.gen_expr(expr.right)
        op = self.CMPOP_STR.get(expr.op, '==')
        return f'({left} {op} {right})'
    
    def gen_call(self, expr: IRCall) -> str:
        """Генерирует вызов функции."""
        func_name = expr.func_name
        args = [self.gen_expr(arg) for arg in expr.args]
        
        # Встроенные math функции
        if func_name in self.MATH_FUNCS:
            cuda_func = self.MATH_FUNCS[func_name]
            return f'{cuda_func}({", ".join(args)})'
        
        # len
        if func_name == 'len':
            if expr.args and isinstance(expr.args[0], IRVar):
                arr_name = expr.args[0].name
                if arr_name in self.array_sizes:
                    return self.array_sizes[arr_name]
                # If List (we can check type of first arg if available in IR?)
                # We could check if expr.args[0].type.is_list().
                # For now, let's just rely on method syntax if possible, or fallback.
                # But 'len(list)' should map to 'list.len()'.
                # We need `expr.args[0]` to check type.
                # Assuming `IRNode` doesn't strictly enforce type presence (might be None if inference skipped).
                # But if we did type inference, it should be there.
                
                # Check for list.len() transformation
                arg0 = expr.args[0]
                if hasattr(arg0, 'type') and arg0.type:
                    if arg0.type.is_list() or arg0.type.kind == TypeKind.STRING:
                        return f'{self.gen_expr(arg0)}.len()'
                    
            return args[0] if args else '0'
        
        # Приведение типов
        if func_name == 'int':
            return f'(int)({args[0]})'
        if func_name == 'float':
            return f'(float)({args[0]})'
        if func_name == 'bool':
            return f'(bool)({args[0]})'
        
        # Пользовательская функция
        return f'{func_name}({", ".join(args)})'
    
    def gen_method_call(self, expr: IRMethodCall) -> str:
        """Генерирует вызов метода."""
        # Check for banned usage of host libraries (cp.zeros, np.array etc)
        if isinstance(expr.obj, IRVar) and expr.obj.name in ('cp', 'np', 'cupy', 'numpy', 'torch'):
             raise CodeGenError(f"Cannot use host Python library '{expr.obj.name}' inside a CUDA kernel. "
                                f"GPU code compiles to C++ and cannot access Python objects. "
                                f"Solution: Allocate arrays on the host and pass them as arguments.")

        obj = self.gen_expr(expr.obj)
        args = [self.gen_expr(arg) for arg in expr.args]
        
        # Если это List и метод поддерживается
        if expr.obj.type and expr.obj.type.is_list():
            if expr.method_name in ('append', 'pop', 'len', 'clear'):
                return f'{obj}.{expr.method_name}({", ".join(args)})'
        
        # Определяем имя структуры
        struct_name = None
        if expr.obj.type:
            if expr.obj.type.is_struct():
                struct_name = expr.obj.type.name
            elif expr.obj.type.is_pointer() and expr.obj.type.element_type:
                struct_name = expr.obj.type.element_type.name
        
        if struct_name:
            if expr.obj.type.is_pointer():
                all_args = [obj] + args
            else:
                all_args = [f'&{obj}'] + args
            return f'{struct_name}_{expr.method_name}({", ".join(all_args)})'
        
        # Fallback
        return f'{obj}.{expr.method_name}({", ".join(args)})'
    
    def gen_index(self, expr: IRIndex) -> str:
        """Генерирует индексацию."""
        obj = self.gen_expr(expr.obj)
        
        if expr.obj.type and expr.obj.type.is_list():
             return f'{obj}[{self.gen_expr(expr.index)}]'
        
        if expr.obj.type and expr.obj.type.kind == TypeKind.TUPLE:
             if isinstance(expr.index, IRConst) and isinstance(expr.index.value, int):
                  return f'{obj}.f{expr.index.value}'
             # Fallback if inference failed or dynamic index (not supported)
             raise CodeGenError("Dynamic tuple indexing not supported")

        index = self.gen_expr(expr.index)
        return f'{obj}[{index}]'
    
    def gen_attr(self, expr: IRAttr) -> str:
        """Генерирует доступ к атрибуту."""
        obj = self.gen_expr(expr.obj)
        
        # self.attr → self->attr
        if isinstance(expr.obj, IRVar) and expr.obj.name == 'self':
            return f'self->{expr.attr_name}'
        
        # Для указателей используем ->
        if expr.obj.type and expr.obj.type.is_pointer():
            return f'{obj}->{expr.attr_name}'
        
        return f'{obj}.{expr.attr_name}'
    
    def gen_ternary(self, expr: IRTernary) -> str:
        """Генерирует тернарный оператор."""
        cond = self.gen_expr(expr.condition)
        then_val = self.gen_expr(expr.then_value)
        else_val = self.gen_expr(expr.else_value)
        return f'({cond} ? {then_val} : {else_val})'
    
    def gen_cast(self, expr: IRCast) -> str:
        """Генерирует приведение типа."""
        inner = self.gen_expr(expr.expr)
        target = self.type_to_cuda(expr.target_type)
        return f'({target})({inner})'
    
    def gen_array_init(self, expr: IRArrayInit) -> str:
        """Генерирует инициализацию массива."""
        elements = [self.gen_expr(e) for e in expr.elements]
        return f'{{{", ".join(elements)}}}'
    
    def gen_array_alloc(self, expr: IRArrayAlloc) -> str:
        """Generates dynamic array allocation (malloc/new)."""
        cuda_type = self.type_to_cuda(expr.element_type)
        
        # np.zeros / np.empty
        if expr.values is None:
             size = self.gen_expr(expr.size)
             if expr.zero_init:
                 return f'new {cuda_type}[{size}]()'
             else:
                 return f'new {cuda_type}[{size}]'
        
        # np.array([values])
        # C++11 initializer list: new int[3]{1, 2, 3}
        if expr.values:
             size = len(expr.values)
             values = [self.gen_expr(v) for v in expr.values]
             return f'new {cuda_type}[{size}]{{{", ".join(values)}}}'
        
        return "NULL"

    
    def gen_struct_init(self, expr: IRStructInit) -> str:
        """Генерирует инициализацию структуры."""
        if expr.field_values:
            fields = [f'.{k} = {self.gen_expr(v)}' for k, v in expr.field_values.items()]
            return f'({expr.struct_name}){{{", ".join(fields)}}}'
        return f'({expr.struct_name}){{0}}'

    def gen_tuple_init(self, expr: IRTupleInit) -> str:
        """Generates tuple initialization."""
        elements = [self.gen_expr(e) for e in expr.elements]
        # Use constructor notation for safety
        if expr.type:
             return f'{expr.type.cuda_name}({", ".join(elements)})'
        return f'{{{", ".join(elements)}}}'

    def gen_optional_struct_def(self, t: CUDAType) -> str:
        """Генерирует определение структуры Optional."""
        elem_type = self.type_to_cuda(t.element_type)
        name = t.cuda_name
        
        return f'''struct {name} {{
    bool has_value;
    {elem_type} value;
    
    __device__ {name}() : has_value(false), value() {{}}
    __device__ {name}({elem_type} v) : has_value(true), value(v) {{}}
}};'''

    def gen_optional_init(self, expr: IROptionalInit) -> str:
        """Генерирует инициализацию Optional."""
        if expr.value is None:
            # None -> default constructor
            return f'{expr.type.cuda_name}()'
        
        # Some(x) -> constructor with value
        val = self.gen_expr(expr.value)
        return f'{expr.type.cuda_name}({val})'

    def gen_string_struct_def(self) -> str:
        """Генерирует определение структуры String."""
        return '''struct String {
    char data[64];
    int length;
    
    __device__ String() : length(0) { data[0] = 0; }
    
    __device__ String(const char* s) {
        length = 0;
        for(int i=0; i<63 && s[i] != 0; ++i) {
            data[i] = s[i];
            length++;
        }
        data[length] = 0;
    }
    
    __device__ int len() const { return length; }
    
    __device__ bool operator==(const String& other) const {
        if (length != other.length) return false;
        for(int i=0; i<length; ++i) {
            if (data[i] != other.data[i]) return false;
        }
        return true;
    }
};'''

    def gen_dict_struct_def(self, t: CUDAType) -> str:
        """Генерирует определение структуры Dict."""
        key_type = self.type_to_cuda(t.element_types[0])
        val_type = self.type_to_cuda(t.element_types[1])
        name = t.cuda_name
        capacity = t.capacity
        
        # Simple hash function generation (inline)
        # Should vary by key type logic? 
        # For now, cast to int logic
        get_hash = "((unsigned)k * 2654435761u)"
        
        return f'''struct {name} {{
    {key_type} keys[{capacity}];
    {val_type} values[{capacity}];
    bool occupied[{capacity}];
    
    __device__ {name}() {{
        for(int i=0; i<{capacity}; ++i) occupied[i] = false;
    }}
    
    __device__ unsigned hash({key_type} k) {{
        return {get_hash};
    }}
    
    __device__ bool contains({key_type} k) {{
        unsigned h = hash(k);
        for(int i=0; i<{capacity}; ++i) {{
             int idx = (h + i) % {capacity};
             if (!occupied[idx]) return false;
             if (occupied[idx] && keys[idx] == k) return true;
        }}
        return false;
    }}
    
    __device__ {val_type}& operator[]({key_type} k) {{
        unsigned h = hash(k);
        for(int i=0; i<{capacity}; ++i) {{
             int idx = (h + i) % {capacity};
             if (!occupied[idx]) {{
                 occupied[idx] = true;
                 keys[idx] = k;
                 // Initialize value? 
                 // Assuming default constructor for value type calls logic? 
                 // Actually C++ POD arrays are not auto-zeroed if just allocated?
                 // But we return reference. User usually assigns to it immediately: d[k] = v.
                 // If reading d[k] (and it's new), it returns uninitialized memory?
                 // Safe to zero init?
                 // values[idx] = {val_type}(); 
                 return values[idx];
             }}
             if (occupied[idx] && keys[idx] == k) {{
                 return values[idx];
             }}
        }}
        return values[0]; // Full
    }}
}};'''

    def gen_set_struct_def(self, t: CUDAType) -> str:
        """Генерирует определение структуры Set."""
        key_type = self.type_to_cuda(t.element_type)
        name = t.cuda_name
        capacity = t.capacity
        
        get_hash = "((unsigned)k * 2654435761u)"
        
        return f'''struct {name} {{
    {key_type} keys[{capacity}];
    bool occupied[{capacity}];
    
    __device__ {name}() {{
        for(int i=0; i<{capacity}; ++i) occupied[i] = false;
    }}
    
    __device__ unsigned hash({key_type} k) {{
        return {get_hash};
    }}
    
    __device__ bool contains({key_type} k) {{
        unsigned h = hash(k);
        for(int i=0; i<{capacity}; ++i) {{
             int idx = (h + i) % {capacity};
             if (!occupied[idx]) return false;
             if (occupied[idx] && keys[idx] == k) return true;
        }}
        return false;
    }}
    
    __device__ void add({key_type} k) {{
        unsigned h = hash(k);
        for(int i=0; i<{capacity}; ++i) {{
             int idx = (h + i) % {capacity};
             if (!occupied[idx]) {{
                 occupied[idx] = true;
                 keys[idx] = k;
                 return;
             }}
             if (occupied[idx] && keys[idx] == k) {{
                 return;
             }}
        }}
    }}
}};'''
